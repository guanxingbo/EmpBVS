{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38439,
     "status": "ok",
     "timestamp": 1756371899093,
     "user": {
      "displayName": "Qishi Dong",
      "userId": "08675026335886676780"
     },
     "user_tz": -480
    },
    "id": "2jwpa4Yxqsjw",
    "outputId": "b283356d-7f90-4e4f-cae6-236a026d8fac"
   },
   "outputs": [],
   "source": [
    "#Simulations and Benchmarking Comparison with LASSO\n",
    "import numpy as np\n",
    "from numpy.linalg import cholesky\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from dataclasses import dataclass\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ---------------------- Config ----------------------\n",
    "N = 500            # samples\n",
    "P = 1000           # total features\n",
    "S = 200            # number of true nonzero features (\"top 200 X_i\")\n",
    "BLOCK = 50         # correlation block size\n",
    "RHO = 0.8          # within-block AR(1) correlation\n",
    "SNR = 16.0          # signal-to-noise ratio: Var(Xb)/Var(eps)\n",
    "NUM_RUNS = 5       # repeat the simulation\n",
    "RANDOM_200 = False # if True, choose 200 random causal features; else first 200\n",
    "SEED = 1234\n",
    "\n",
    "# ------------------- Simulation utils ----------------\n",
    "def make_block_ar1_X(n, p, block=50, rho=0.6, rng=None):\n",
    "    \"\"\"\n",
    "    Generate X with blockwise AR(1) correlation across features.\n",
    "    Each block has covariance Sigma_ij = rho^{|i-j|}.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    X = np.zeros((n, p), dtype=float)\n",
    "    num_blocks = int(np.ceil(p / block))\n",
    "    for b in range(num_blocks):\n",
    "        s = b * block\n",
    "        e = min((b + 1) * block, p)\n",
    "        m = e - s\n",
    "        # AR(1) covariance and Cholesky\n",
    "        idx = np.arange(m)\n",
    "        Sigma = rho ** np.abs(idx[:, None] - idx[None, :])\n",
    "        L = cholesky(Sigma + 1e-8 * np.eye(m))\n",
    "        Z = rng.standard_normal(size=(n, m))\n",
    "        X[:, s:e] = Z @ L.T\n",
    "    # standardize columns to mean 0, var 1\n",
    "    X -= X.mean(axis=0, keepdims=True)\n",
    "    std = X.std(axis=0, ddof=1, keepdims=True)\n",
    "    std[std == 0] = 1.0\n",
    "    X /= std\n",
    "    return X\n",
    "\n",
    "def simulate_linear(X, s=200, snr=8.0, random_200=False, rng=None):\n",
    "    \"\"\"\n",
    "    Choose s causal features, draw coefficients, create y with target SNR.\n",
    "    Returns: y, beta_true, support (boolean mask).\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    n, p = X.shape\n",
    "    support = np.zeros(p, dtype=bool)\n",
    "    if random_200:\n",
    "        idx = rng.choice(p, size=s, replace=False)\n",
    "    else:\n",
    "        idx = np.arange(s)  # \"top 200\" = first 200 columns\n",
    "    support[idx] = True\n",
    "\n",
    "    beta = np.zeros(p, dtype=float)\n",
    "    # effect sizes: random signs & magnitudes\n",
    "    beta[idx] = rng.choice([-1, 1], size=s) * (0.5 + rng.random(s))\n",
    "\n",
    "    y_signal = X @ beta\n",
    "    var_signal = y_signal.var()\n",
    "    var_noise = var_signal / snr if snr > 0 else 1.0\n",
    "    eps = rng.standard_normal(n) * np.sqrt(var_noise)\n",
    "    y = y_signal + eps\n",
    "    # standardize y (optional; LASSO pipeline will standardize anyway)\n",
    "    return y, beta, support\n",
    "\n",
    "def fit_lasso_select(X, y, seed=0):\n",
    "    \"\"\"\n",
    "    LASSO with CV; return indices selected (nonzero coefficients).\n",
    "    \"\"\"\n",
    "    pipe = make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "        LassoCV(cv=5, alphas=100, random_state=seed, max_iter=10000)\n",
    "    )\n",
    "    pipe.fit(X, y)\n",
    "    coef = pipe.named_steps['lassocv'].coef_\n",
    "    selected = np.flatnonzero(np.abs(coef) > 1e-10)\n",
    "    return selected, coef\n",
    "\n",
    "@dataclass\n",
    "class Metrics:\n",
    "    tp: int; fp: int; fn: int; tn: int\n",
    "    tpr: float; fpr: float\n",
    "    selected: int\n",
    "\n",
    "def compute_tpr_fpr(selected_idx, support_mask, p_total):\n",
    "    \"\"\"\n",
    "    TPR = TP / (#true); FPR = FP / (#null).\n",
    "    \"\"\"\n",
    "    selected_mask = np.zeros(p_total, dtype=bool)\n",
    "    selected_mask[selected_idx] = True\n",
    "\n",
    "    tp = int(np.sum(selected_mask & support_mask))\n",
    "    fp = int(np.sum(selected_mask & ~support_mask))\n",
    "    fn = int(np.sum(~selected_mask & support_mask))\n",
    "    tn = int(np.sum(~selected_mask & ~support_mask))\n",
    "\n",
    "    s = int(np.sum(support_mask))\n",
    "    nulls = p_total - s\n",
    "    tpr = tp / s if s > 0 else np.nan\n",
    "    fpr = fp / nulls if nulls > 0 else np.nan\n",
    "    return Metrics(tp, fp, fn, tn, tpr, fpr, int(np.sum(selected_mask)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1756371909333,
     "user": {
      "displayName": "Qishi Dong",
      "userId": "08675026335886676780"
     },
     "user_tz": -480
    },
    "id": "VdUxGvBrzIrM"
   },
   "outputs": [],
   "source": [
    "#Our methods\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    cp.random.seed(seed)\n",
    "set_seed(123)\n",
    "\n",
    "class fixed_variable_selection:\n",
    "    def __init__(self,data,prior):\n",
    "      self.data=data\n",
    "      self.p_lambda=prior[0]\n",
    "      self.p_wishart=prior[1]\n",
    "      self.p_probability=prior[2]\n",
    "\n",
    "    def dot(self,A,B):\n",
    "      C=cp.einsum('ijk,ikp->ijp', A, B)\n",
    "      return C\n",
    "\n",
    "    def quantity(self,data):\n",
    "      X,Y=data\n",
    "      N,P=X.shape\n",
    "      D=Y.shape[1]\n",
    "      #Q1: sum n of xni^2 P*1\n",
    "      #Q2: sum of Yn*Yn^T D*D\n",
    "      #Q3: sum n of xni*Yn D*P\n",
    "      #Q4: sum of n xni*xnj P*P\n",
    "\n",
    "      Q1=cp.sum(X*X,axis=0).reshape(P,1)\n",
    "      Q2=cp.sum(Y.reshape(N,D,1)*Y.reshape(N,1,D),axis=0)\n",
    "      Q3=cp.sum(X.reshape(N,1,P)*Y.reshape(N,D,1),axis=0)\n",
    "      for i in range(N):\n",
    "          if i==0:\n",
    "                Q4=X[i].reshape(P,1)*X[i].reshape(1,P)\n",
    "          else:\n",
    "            Q4+=X[i].reshape(P,1)*X[i].reshape(1,P)\n",
    "      return [Q1,Q2,Q3,Q4]\n",
    "\n",
    "\n",
    "    def VI_w(self,data,E_lambda,E_w_p,E_z,p_lambda,Q):\n",
    "      X,Y=data\n",
    "      N,P=X.shape\n",
    "      D=Y.shape[1]\n",
    "      #X:N*P\n",
    "      #Y:N*D\n",
    "      #E_lambda:D*D\n",
    "      #E_w_p:D*P\n",
    "      #E_z:P*2\n",
    "      #p_lambda[0]:D*D (identity matrix)\n",
    "\n",
    "      #precision:P*D*D\n",
    "      precision=Q[0].reshape(P,1,1)*E_lambda+E_z[:,0].reshape(P,1,1)*p_lambda[0]+E_z[:,1].reshape(P,1,1)*p_lambda[1]\n",
    "      inv_precision=cp.linalg.inv(precision+1e-11)\n",
    "\n",
    "      mu_i1=X.reshape(N,1,P)*E_w_p #N*D*P\n",
    "      mu_inter=cp.sum(X.reshape(N,1,P)*(cp.sum(mu_i1,axis=-1,keepdims=True)-mu_i1),axis=0)-Q[2] #D*P\n",
    "      mu_inter2=-cp.sum(E_lambda*cp.transpose(mu_inter).reshape(P,1,D),axis=-1).reshape(P,1,D) #P*D\n",
    "      mu=cp.sum(inv_precision*mu_inter2,axis=-1) #P*D\n",
    "\n",
    "      def Gaussian_expectation(mean,precision,inv_precision):\n",
    "        E_w=mean\n",
    "        E_w_2=mean.reshape(P,D,1)*mean.reshape(P,1,D)+inv_precision\n",
    "        return [cp.transpose(E_w),E_w_2,mean,inv_precision] #D*P, P*D*D\n",
    "\n",
    "      return Gaussian_expectation(mu,precision,inv_precision)\n",
    "\n",
    "\n",
    "    def VI_z(self,E_w_2,p_lambda,p):\n",
    "      #E_w_2:P*D*D\n",
    "      #p_lambda[0]:D*D\n",
    "      D=p_lambda[0].shape[0]\n",
    "      #p:constant 0.5\n",
    "      p_lambda1=cp.repeat(p_lambda[0].reshape(1,D,D),len(E_w_2),axis=0)\n",
    "      p_lambda2=cp.repeat(p_lambda[1].reshape(1,D,D),len(E_w_2),axis=0)\n",
    "     # print(E_w_2)\n",
    "\n",
    "      z_1=0.5*cp.log(cp.linalg.det(p_lambda[0]))-0.5*cp.trace(self.dot(p_lambda1,E_w_2),axis1=-2, axis2=-1).reshape(-1,1)+cp.log(p+1e-20) #P*1\n",
    "     # print(z_1)\n",
    "      z_2=0.5*cp.log(cp.linalg.det(p_lambda[1]))-0.5*cp.trace(self.dot(p_lambda2,E_w_2),axis1=-2, axis2=-1).reshape(-1,1)+cp.log(1-p+1e-20) #P*1\n",
    "\n",
    "      z=1/(1+cp.exp(z_2-z_1))\n",
    "      #print(z[0])\n",
    "      return cp.concatenate([z,1-z],axis=1)\n",
    "\n",
    "    def VI_lambda(self,data,E_w,inv_precision,p_v,p_V,Q):\n",
    "      X,Y=data\n",
    "      N,P=X.shape\n",
    "      D=Y.shape[1]\n",
    "\n",
    "      E_w_t=cp.transpose(E_w)\n",
    "      #E_w_t:P*D\n",
    "      #inv_precision:P*D*D\n",
    "      #p_v:constant\n",
    "      #p_V:D*D\n",
    "\n",
    "      new_v=p_v+N\n",
    "      new_V_i=cp.linalg.inv(p_V)+Q[1]-cp.sum(self.dot(E_w_t.reshape(P,D,1),cp.transpose(Q[2]).reshape(P,1,D)),axis=0)\\\n",
    "        -cp.sum(self.dot(cp.transpose(Q[2]).reshape(P,D,1),E_w_t.reshape(P,1,D)),axis=0) #D*D\n",
    "\n",
    "      new_V_i1=E_w_t.reshape(P,1,D,1)*E_w_t.reshape(1,P,1,D) #P*P*D*D\n",
    "      for i in range(P):\n",
    "        new_V_i1[i,i,:,:]+=inv_precision[i]\n",
    "\n",
    "      new_V_i2=cp.sum(Q[3].reshape(P,P,1,1)*new_V_i1,axis=[0,1])#D*D\n",
    "\n",
    "      new_V=(new_V_i2+cp.transpose(new_V_i2))/2+new_V_i\n",
    "\n",
    "      def wishart_expectation(v,V):\n",
    "        return [v*cp.linalg.inv(V),v,cp.linalg.inv(V)]\n",
    "\n",
    "      return wishart_expectation(new_v,new_V)\n",
    "\n",
    "    def variational_inference(self,max_iter,last_run,activate=True):\n",
    "      if len(last_run)==0:\n",
    "\n",
    "        def initialization():\n",
    "\n",
    "          from sklearn import linear_model\n",
    "          regr = linear_model.LinearRegression()\n",
    "          regr.fit(cp.asnumpy(self.data[0]),cp.asnumpy(self.data[1]))\n",
    "          regr.coef_\n",
    "          i_E_w=cp.array(regr.coef_) #D*P\n",
    "        #  i_E_w=cp.concatenate([beta.reshape(1,-1),cp.zeros((750,1)).reshape(1,-1)],axis=1).reshape(1,P+1)\n",
    "          i_E_w_2=cp.transpose(i_E_w).reshape(-1,self.data[1].shape[1],1)*cp.transpose(i_E_w).reshape(-1,1,self.data[1].shape[1]) #P*D*D\n",
    "\n",
    "          return i_E_w,i_E_w_2,cp.zeros_like(i_E_w_2) #inv_precision\n",
    "\n",
    "        E_w,E_w_2,inv_precision=initialization()\n",
    "        self.Q=self.quantity(self.data)\n",
    "\n",
    "      else:\n",
    "\n",
    "        E_w,E_w_2,inv_precision,self.p_probability,self.p_wishart=last_run\n",
    "\n",
    "      for i in range(max_iter):\n",
    "        E_lambda,c_v,c_V=self.VI_lambda(self.data,E_w,inv_precision,self.p_wishart[0],self.p_wishart[1],self.Q) #P*D*D\n",
    "\n",
    "        E_z=self.VI_z(E_w_2,self.p_lambda,self.p_probability) #P*2\n",
    "        c_E_w,E_w_2,c_mu,inv_precision=self.VI_w(self.data,E_lambda,E_w,E_z,self.p_lambda,self.Q)\n",
    "\n",
    "        E_w=c_E_w #P*D\n",
    "\n",
    "        Stop=self.early_stop(E_z,i,1e-5,activate)\n",
    "\n",
    "        if Stop:\n",
    "            return [E_z,E_w,E_lambda],[E_w,E_w_2,inv_precision,E_z[:,0].reshape(-1,1),[c_v,c_V]]\n",
    "        if i==max_iter-1:\n",
    "            return [E_z,E_w,E_lambda],[E_w,E_w_2,inv_precision,E_z[:,0].reshape(-1,1),[c_v,c_V]]\n",
    "\n",
    "\n",
    "    def sampling_batch(self,iter_s,inner_iter,sub_set,activate=True):\n",
    "\n",
    "        import random\n",
    "        for i in range(iter_s):\n",
    "            if i ==0:\n",
    "              def initialization():\n",
    "                  from sklearn import linear_model\n",
    "                  regr = linear_model.LinearRegression()\n",
    "                  regr.fit(cp.asnumpy(self.data[0]),cp.asnumpy(self.data[1]))\n",
    "                  regr.coef_\n",
    "                  i_E_w=cp.array(regr.coef_) #D*P\n",
    "                #  i_E_w=cp.concatenate([beta.reshape(1,-1),cp.zeros((750,1)).reshape(1,-1)],axis=1).reshape(1,P+1)\n",
    "                  i_E_w_2=cp.transpose(i_E_w).reshape(-1,self.data[1].shape[1],1)*cp.transpose(i_E_w).reshape(-1,1,self.data[1].shape[1]) #P*D*D\n",
    "                  return i_E_w,i_E_w_2,cp.zeros_like(i_E_w_2) #inv_precision\n",
    "\n",
    "              E_w,E_w_2,inv_precision=initialization()\n",
    "              last_run=[E_w,E_w_2,inv_precision,self.p_probability,self.p_wishart]\n",
    "              self.entire_data=self.data\n",
    "\n",
    "              entire_order = list(range(self.entire_data[0].shape[0]))\n",
    "              random.shuffle(entire_order)\n",
    "              rank = entire_order[-subset:]\n",
    "              del entire_order[-subset:]\n",
    "\n",
    "              #rank=random.sample(range(0,self.entire_data[0].shape[0]),sub_set)\n",
    "              self.data=[self.entire_data[0][rank],self.entire_data[1][rank]]\n",
    "              self.Q=self.quantity(self.data)\n",
    "\n",
    "              e_moment,last_run=self.variational_inference(inner_iter,last_run,False)\n",
    "\n",
    "            else:\n",
    "\n",
    "              rank = entire_order[-subset:]\n",
    "              del entire_order[-subset:]\n",
    "              if len(entire_order)<subset:\n",
    "                    entire_order = list(range(self.entire_data[0].shape[0]))\n",
    "\n",
    "              self.data=[self.entire_data[0][rank],self.entire_data[1][rank]]\n",
    "              self.Q=self.quantity(self.data)\n",
    "\n",
    "              e_moment,last_run=self.variational_inference(inner_iter,last_run,False)\n",
    "            Stop=self.early_stop(e_moment[0],i,1e-5,activate=True)\n",
    "\n",
    "            if Stop:\n",
    "                return e_moment,last_run\n",
    "            if i==iter_s-1:\n",
    "                return e_moment,last_run\n",
    "\n",
    "\n",
    "    def VIEM(self,max_iter,inner_iter):\n",
    "      for i in range(max_iter):\n",
    "        if i ==0:\n",
    "          e_moment,last_run=self.variational_inference(inner_iter,[])\n",
    "        else:\n",
    "          e_moment,last_run=self.variational_inference(inner_iter,last_run)\n",
    "\n",
    "      return e_moment\n",
    "\n",
    "    def early_stop(self,E_z,iteration,threshold,activate=True):\n",
    "\n",
    "        if activate:\n",
    "            if iteration<5:\n",
    "                if iteration==0:\n",
    "                    global moving_container\n",
    "                    moving_container=cp.expand_dims(E_z,axis=0)\n",
    "                else:\n",
    "                    moving_container=cp.concatenate([moving_container,cp.expand_dims(E_z,axis=0)],axis=0)\n",
    "            else:\n",
    "                MV=cp.mean(moving_container,axis=0)\n",
    "                if cp.sum(MV-E_z)<threshold:\n",
    "                    print('Converged')\n",
    "                    return True\n",
    "\n",
    "                else:\n",
    "                    moving_container=cp.concatenate([moving_container,cp.expand_dims(E_z,axis=0)],axis=0)[1:]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "def construct_prior(data,sampling=True):\n",
    "    X,Y=data\n",
    "    N,P=X.shape\n",
    "    D=Y.shape[1]\n",
    "\n",
    "    p=cp.repeat(cp.array([[0.5]]),P,axis=0)\n",
    "    v_0=D\n",
    "    V_0=cp.identity(D)\n",
    "\n",
    "    p_lambda2=cp.sum(cp.var(Y,axis=0))*cp.identity(D)/(D*10*N)\n",
    "    if cp.log(cp.array(N))>=cp.array((P*D)**2.1/(100.*N)):\n",
    "        argmax=cp.log(cp.array(N))\n",
    "    else:\n",
    "        argmax=cp.array(((P*D)**2.1)/(100.*N))\n",
    "\n",
    "    p_lambda1=(cp.sum(cp.var(Y,axis=0))*argmax/D)*cp.identity(D)\n",
    "\n",
    "\n",
    "#     p_lambda1=5*cp.identity(D)\n",
    "#     p_lambda2=0.05*cp.identity(D)\n",
    "    if sampling:\n",
    "        p_lambda1=5*cp.identity(D)\n",
    "        p_lambda2=0.2*cp.identity(D)\n",
    "    else:\n",
    "        p_lambda1=5*cp.identity(D)\n",
    "        p_lambda2=0.05*cp.identity(D)\n",
    "    #   print(1/p_lambda1)\n",
    "    #   print(1/p_lambda2)\n",
    "\n",
    "    return [[cp.linalg.inv(p_lambda1),cp.linalg.inv(p_lambda2)],[v_0,V_0],p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[run 1/5] selected=217 | TP=113 FP=104 FN=87 TN=696 | TPR=0.565 FPR=0.130\n",
      "[run 2/5] selected=254 | TP=107 FP=147 FN=93 TN=653 | TPR=0.535 FPR=0.184\n",
      "[run 3/5] selected=183 | TP=95 FP=88 FN=105 TN=712 | TPR=0.475 FPR=0.110\n",
      "[run 4/5] selected=221 | TP=105 FP=116 FN=95 TN=684 | TPR=0.525 FPR=0.145\n",
      "[run 5/5] selected=251 | TP=117 FP=134 FN=83 TN=666 | TPR=0.585 FPR=0.168\n",
      "\n",
      "== Averages over runs ==\n",
      "avg selected: 225.2 | avg TPR: 0.537 | avg FPR: 0.147\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Simulation Studies using LASSO -----------------\n",
    "rng = np.random.default_rng(SEED)\n",
    "all_metrics = []\n",
    "\n",
    "for run in range(NUM_RUNS):\n",
    "    # 1) simulate X and y\n",
    "    X = make_block_ar1_X(N, P, block=BLOCK, rho=RHO, rng=rng)\n",
    "    y, beta_true, support = simulate_linear(\n",
    "        X, s=S, snr=SNR, random_200=RANDOM_200, rng=rng\n",
    "    )\n",
    "\n",
    "    # 2) variable selection via LASSO\n",
    "    sel_idx, coef = fit_lasso_select(X, y, seed=SEED + run)\n",
    "\n",
    "    # 3) metrics\n",
    "    m = compute_tpr_fpr(sel_idx, support, P)\n",
    "    all_metrics.append(m)\n",
    "\n",
    "    print(f\"[run {run+1}/{NUM_RUNS}] selected={m.selected} | TP={m.tp} FP={m.fp} \"\n",
    "          f\"FN={m.fn} TN={m.tn} | TPR={m.tpr:.3f} FPR={m.fpr:.3f}\")\n",
    "\n",
    "# 4) report averages\n",
    "avg_tpr = np.mean([m.tpr for m in all_metrics])\n",
    "avg_fpr = np.mean([m.fpr for m in all_metrics])\n",
    "avg_sel = np.mean([m.selected for m in all_metrics])\n",
    "print(\"\\n== Averages over runs ==\")\n",
    "print(f\"avg selected: {avg_sel:.1f} | avg TPR: {avg_tpr:.3f} | avg FPR: {avg_fpr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12548,
     "status": "ok",
     "timestamp": 1756371854726,
     "user": {
      "displayName": "Qishi Dong",
      "userId": "08675026335886676780"
     },
     "user_tz": -480
    },
    "id": "rL0cbCZkr6Em",
    "outputId": "3d68d467-ba29-4f7f-f0ee-fed3b5f4ef61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[run 1/5] selected=227 | TP=101 FP=126 FN=99 TN=674 | TPR=0.505 FPR=0.158\n",
      "[run 2/5] selected=171 | TP=99 FP=72 FN=101 TN=728 | TPR=0.495 FPR=0.090\n",
      "[run 3/5] selected=185 | TP=123 FP=62 FN=77 TN=738 | TPR=0.615 FPR=0.077\n",
      "[run 4/5] selected=134 | TP=96 FP=38 FN=104 TN=762 | TPR=0.480 FPR=0.048\n",
      "[run 5/5] selected=139 | TP=98 FP=41 FN=102 TN=759 | TPR=0.490 FPR=0.051\n",
      "\n",
      "== Averages over runs ==\n",
      "avg selected: 171.2 | avg TPR: 0.517 | avg FPR: 0.085\n"
     ]
    }
   ],
   "source": [
    "#Simulations Studies using our methods\n",
    "rng = np.random.default_rng(SEED)\n",
    "all_metrics = []\n",
    "\n",
    "for run in range(5):\n",
    "    # 1) simulate X and y\n",
    "    X = make_block_ar1_X(N, P, block=BLOCK, rho=RHO, rng=rng)\n",
    "    y, beta_true, support = simulate_linear(\n",
    "        X, s=S, snr=SNR, random_200=RANDOM_200, rng=rng\n",
    "    )\n",
    "\n",
    "    # 2) variable selection via our method\n",
    "    prior = construct_prior([cp.array(X),cp.array(y.reshape(-1,1))])\n",
    "    e_moment = fixed_variable_selection([cp.array(X),cp.array(y.reshape(-1,1))], prior).VIEM(30,1)\n",
    "    sel_idx = np.flatnonzero(cp.asnumpy(e_moment[0][:, 0]) > 0.99)\n",
    "\n",
    "    # 3) metrics\n",
    "    m = compute_tpr_fpr(sel_idx, support, P)\n",
    "    all_metrics.append(m)\n",
    "\n",
    "    print(f\"[run {run+1}/{NUM_RUNS}] selected={m.selected} | TP={m.tp} FP={m.fp} \"\n",
    "          f\"FN={m.fn} TN={m.tn} | TPR={m.tpr:.3f} FPR={m.fpr:.3f}\")\n",
    "\n",
    "# 4) report averages\n",
    "avg_tpr = np.mean([m.tpr for m in all_metrics])\n",
    "avg_fpr = np.mean([m.fpr for m in all_metrics])\n",
    "avg_sel = np.mean([m.selected for m in all_metrics])\n",
    "print(\"\\n== Averages over runs ==\")\n",
    "print(f\"avg selected: {avg_sel:.1f} | avg TPR: {avg_tpr:.3f} | avg FPR: {avg_fpr:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMZZ3vnoHzCFC5U5to0udin",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
